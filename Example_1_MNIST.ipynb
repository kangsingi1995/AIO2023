{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8oH1HAxGpEVYMgW3aArMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kangsingi1995/AIO2023/blob/main/Example_1_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "de7pbWvbtTYH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "\n",
        "ROOT = './data'\n",
        "train_data = datasets.MNIST(\n",
        "    root = ROOT,\n",
        "    train = True,\n",
        "    download = True\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = ROOT,\n",
        "    train = False,\n",
        "    download = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Tiền xử lý dữ liệu\n",
        "- Chia tỉ lệ các tập training: validation = 0.9 : 0.1\n",
        "- Chuẩn hoá dữ liệu và chuyển sang tensor sử dụng torchvison.transform"
      ],
      "metadata": {
        "id": "B8oQEyQ9pQfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#chia tỷ lệ training và validation = 0.9:0.1\n",
        "VALID_RATIO = 0.9\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(\n",
        "    train_data,\n",
        "    [n_train_examples, n_valid_examples]\n",
        ")\n",
        "\n",
        "# Tính trung bình và độ lệch chuẩn cho việc chuẩn hoá dữ liệu\n",
        "mean = train_data.dataset.data.float().mean() / 255\n",
        "std = train_data.dataset.data.float().std() / 255\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [mean], std=[std])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[mean], std = [std])\n",
        "])\n",
        "\n",
        "train_data.dataset.transform = train_transforms\n",
        "valid_data.dataset.transform = test_transforms\n",
        "\n",
        "# Create dataloader\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_data,\n",
        "    shuffle = True,\n",
        "    batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_dataloader = data.DataLoader(\n",
        "    valid_data,\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "id": "hQTwJPuytVp9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Xây dựng mô hình LeNet"
      ],
      "metadata": {
        "id": "6Y_yJudBxT6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNetClassifier(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(\n",
        "    in_channels = 1, out_channels = 6, kernel_size = 5, padding = 'same'\n",
        "    )\n",
        "    self.avgpool1 = nn.AvgPool2d(kernel_size = 2)\n",
        "    self.conv2 = nn.Conv2d( in_channels = 6, out_channels = 16, kernel_size = 5)\n",
        "    self.avgpool2 = nn.AvgPool2d( kernel_size = 2)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc_1 = nn.Linear(16 * 4 * 4, 120)\n",
        "    self.fc_2 = nn.Linear(120, 84)\n",
        "    self.fc_3 = nn.Linear(84, num_classes )\n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    outputs = self.conv1(inputs)\n",
        "    outputs = self.avgpool1(outputs)\n",
        "    outputs = F.relu(outputs)\n",
        "    outputs = self.conv2(outputs)\n",
        "    outputs = self.avgpool2(outputs)\n",
        "    outputs = F.relu(outputs)\n",
        "    outputs = self.flatten(outputs)\n",
        "    outputs = self.fc_1(outputs)\n",
        "    outputs = self.fc_2(outputs)\n",
        "    outputs = self.fc_3(outputs)\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "Iie-NgFz1ofl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Huấn luyện mô hình"
      ],
      "metadata": {
        "id": "oGVrmnKl4LT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "\n",
        "def train(model, optimizer, cretirion, train_dataloader, device, epoch = 0, log_interval = 50):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0, 0\n",
        "  losses = []\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (inputs, labels) in enumerate (train_dataloader):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    print(inputs)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    #compute loss\n",
        "    loss = criterion(predictions, labels)\n",
        "    lossed.append(loss.item())\n",
        "\n",
        "    #backward\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "    optimizer.step()\n",
        "    total_acc += (predictions.argmax(1) == labels).sum().item()\n",
        "    total_count += labels.size(0)\n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(\n",
        "          \"| epoch {:3d} | {:5d|/{:5d} batches \"\n",
        "          \"| accuracy {:8.3f}\".format(\n",
        "              epoch, idx, len(train_dataloader), total_acc / total_count\n",
        "          )\n",
        "      )\n",
        "      total_acc, total_count = 0, 0\n",
        "      start_time = time.time()\n",
        "\n",
        "    epoch_acc = total_acc / total_count\n",
        "    start_time = time.time()\n",
        "    return epoch_acc, epoch_loss\n",
        "\n",
        "\n",
        "#Evaluation function\n",
        "def evaluate(model, criterion, valid_dataloader):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  losses=[]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      predictions  =model(inputs)\n",
        "\n",
        "      loss = criterion(predictions, labels)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      total_acc += (predictions.argmax(1)==labels).sum().item()\n",
        "      total_count += labels.size(0)\n",
        "\n",
        "  epoch_acc = total_acc/total_count\n",
        "  epoch_loss = sum(losses)/len(losses)\n",
        "  return epoch_acc, epoch_loss"
      ],
      "metadata": {
        "id": "0HCRlmh1vqAO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "KzRL__oZgHRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_data.dataset.classes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else'cpu')\n",
        "\n",
        "lenet_model = LeNetClassifier(num_classes)\n",
        "lenet_model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lenet_model.parameters())\n",
        "\n",
        "num_epochs = 10\n",
        "save_model ='./ model'\n",
        "\n",
        "train_accs, train_losses = [], []\n",
        "eval_accs, eval_losses = [], []\n",
        "best_loss_eval = 100"
      ],
      "metadata": {
        "id": "3kD2CCLDtxh5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4do_YoruS1w",
        "outputId": "ebe76e81-488a-41e6-e708-2febc18259ee"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7ab68edb7490>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, num_epochs +1) :\n",
        "  epoch_start_time = time.time()\n",
        "  # Training\n",
        "  train_acc, train_loss = train(lenet_model, optimizer, criterion, train_dataloader, device, epoch)\n",
        "  train_accs.append(train_acc)\n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  # Evaluation\n",
        "  eval_acc , eval_loss = evaluate(lenet_model , criterion , valid_dataloader)\n",
        "  eval_accs.append(eval_acc)\n",
        "  eval_losses.append(eval_loss)\n",
        "\n",
        "  # Save best model\n",
        "  if eval_loss < best_loss_eval :\n",
        "    torch.save(lenet_model.state_dict() , save_model +'/ lenet_model.pt')\n",
        "\n",
        "  # Print loss , acc end epoch\n",
        "  print(\"-\" * 59)\n",
        "  print(\n",
        "  \"| End of epoch {:3 d} | Time : {:5.2 f}s | Train Accuracy {:8.3 f} | Train Loss {:8.3 f} \"\n",
        "  \"| Valid Accuracy {:8.3 f} | Valid Loss {:8.3 f} \".format(\n",
        "  epoch , time.time() - epoch_start_time , train_acc , train_loss , eval_acc , eval_loss)\n",
        "  )\n",
        "  print(\"-\" * 59)\n",
        "\n",
        "  # Load best model\n",
        "  lenet_model.load_state_dict(torch.load(save_model +'/ lenet_model.pt'))\n",
        "  lenet_model.eval()"
      ],
      "metadata": {
        "id": "PTFRCeImMbaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0021a49a-6228-40e7-ab04-020b21b1ad67"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          ...,\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
            "\n",
            "\n",
            "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          ...,\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
            "\n",
            "\n",
            "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          ...,\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          ...,\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
            "\n",
            "\n",
            "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          ...,\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]],\n",
            "\n",
            "\n",
            "        [[[-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          ...,\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241],\n",
            "          [-0.4241, -0.4241, -0.4241,  ..., -0.4241, -0.4241, -0.4241]]]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (256x400 and 256x120)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8a89839c62b1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-507bc24749ff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, cretirion, train_dataloader, device, epoch, log_interval)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-fb798efb68cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x400 and 256x120)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|"
      ],
      "metadata": {
        "id": "ESSC3JA_fYHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}